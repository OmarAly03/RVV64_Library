# Tiny-YOLOv2 Inference with RVV Vectorized Kernels

This project implements **Tiny-YOLOv2** endâ€‘toâ€‘end object detection using custom **RISCâ€‘V Vector (RVV 1.0) kernels**.  
It mirrors a standard Tinyâ€‘YOLOv2 ONNX model and runs:

* A native **C++ RVV implementation** for detection on RISCâ€‘V (via QEMU).

The goal is to validate and demonstrate RVVâ€‘accelerated convolutional workloads on a realistic detection model.

---

## ðŸ— Project Structure

The Tinyâ€‘YOLOv2 project is organized around a C++ inference pipeline, model parameter extraction, and visualization utilities:

```text
models/tiny-yolov2
â”œâ”€â”€ main.cpp                     # C++ entry point (runs Tiny-YOLOv2 on an image)
â”œâ”€â”€ Makefile                     # Build + run helpers (C++ + analysis)
â”œâ”€â”€ README.md                    # This documentation
â”œâ”€â”€ TinyYolov2.png               # Architecture / model diagram (reference)
â”œâ”€â”€ visualize_results.py         # Python script to overlay and visualize detections
â”‚
â”œâ”€â”€ images/                      # Input test images (host format, e.g., JPG)
â”‚   â”œâ”€â”€ cat.jpg
â”‚   â”œâ”€â”€ man.jpg
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ image_binaries/              # Preprocessed binary images for C++ input
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ kernels.hpp              # Declarations of RVV/scalar kernels
â”‚   â”œâ”€â”€ model.hpp                # High-level model driver
â”‚   â””â”€â”€ yolo_model.hpp           # Tiny-YOLOv2 network definition
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ kernels.cpp              # RVV/scalar kernel implementations
â”‚   â”œâ”€â”€ model.cpp                # Orchestration: weights, network, outputs
â”‚   â”œâ”€â”€ extract_image.py         # Convert images/* -> image_binaries/*.bin
â”‚   â””â”€â”€ extract_weights.py       # Extract .bin weights from tinyyolov2.onnx
â”‚
â”œâ”€â”€ model_parameters/            # Extracted weights and biases (.bin files)
â”‚
â”œâ”€â”€ onnx_model/
â”‚   â””â”€â”€ tinyyolov2.onnx          # Reference ONNX Tiny-YOLOv2 model
â”‚
â”œâ”€â”€ output_files/                # Raw C++ outputs (feature maps, predictions)
â”‚
â””â”€â”€ output_images/               # Visualized detection overlays (PNG/JPG)

```

---

## Getting Started

### Prerequisites

On the host (x86 or other nonâ€‘RISCâ€‘V machine):

1. **RISC-V Toolchain**: To compile C++ with RVV support.
* `riscv64-unknown-linux-gnu-g++` with `-march=rv64gcv -mabi=lp64d`


2. **QEMU (user mode)**: To run the staticallyâ€‘linked RVV binary.
* `qemu-riscv64 -cpu rv64,v=true`


3. **Python 3.x**: For preprocessing and visualization (`numpy`, `Pillow`).

> [!NOTE]
> You do not need a full RISCâ€‘V Linux system image; Tinyâ€‘YOLOv2 is run via userâ€‘mode QEMU on a staticallyâ€‘linked binary.

### ðŸ›  Makefile Actions

The Makefile orchestrates the typical workflow:

| Command | Action |
| --- | --- |
| `make` | Build the C++ Tinyâ€‘YOLOv2 binary with RVV support. |
| `make run IMG=<name>` | Run C++ inference under QEMU on `images/<name>.jpg`. |
| `make extract_weights` | Run `src/extract_weights.py` to populate `model_parameters/`. |
| `make extract_images` | Convert `images/*.jpg` to `image_binaries/*.bin`. |
| `make clean` | Remove compiled binaries and temporary build objects. |

---

## Model Assets

### ONNX Model

The reference Tinyâ€‘YOLOv2 network drives the layout of `model_parameters/*.bin` and the C++ network wiring.

### Weights & Biases

Populated by `src/extract_weights.py`, these are stored as **littleâ€‘endian IEEEâ€‘754 floats (float32)**.

### Test Images

`src/extract_image.py` processes JPEGs into C++-friendly binaries:

1. **Resize/Letterbox** to resolution.
2. **Convert** to RGB float32.
3. **Normalize**

---

## Implementation Details

### Tinyâ€‘YOLOv2 Architecture

The C++ implementation reproduces:

* **Convolution**: Stride and padding matching ONNX.
* **Nonlinearities**: LeakyReLU.
* **Max Pooling**.
* **Final YOLO head**:  tensor decoding.

### RVV Usage

All heavy operations use RVV intrinsics wrapped by generic helpers in the `/lib` directory:

* **Vectorized convolutions**: Inner products over channels and kernels.
* **Vectorized activation**: Batched LeakyReLU.
* **Memory operations**: Vectorized loads/stores and slides.

---

## Visualization and Outputs

`visualize_results.py` reconstructs bounding boxes, applies NMS (Non-maximum suppression), and draws labels.

**Example workflow:**

```bash
# Run C++ inference on cat.jpg
make run IMG=cat
```

---

## Typical Workflow

```bash
cd models/tiny-yolov2

make extract_weights
make extract_images
make
make run IMG=cat
# Result saved to output_images/output_detected_cat.jpg

```

---
